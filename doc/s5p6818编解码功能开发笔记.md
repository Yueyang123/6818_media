[toc]

# H264编码
 首先要弄明白编码的目的，有目的的学习效率会更好。编码是为了将数据进行压缩，这样在传输的过程中就不会使资源被浪费，用一个简单的例子来说明编码的必要性：
        当你此刻显示器正在播放一个视频，分辨率是1280*720，帧率是25，那么一秒所产生正常的数据大小为：
         1280*720(位像素)*25(张) / 8(1字节8位)(结果:B) / 1024(结果:KB) / 1024 (结果:MB) =  2.75MB
        显然一秒这么大的数据你是无法接受的，所以如果不将数据进行压缩，那么只能一首凉凉表达此刻的感受了；

H264编码标准中所遵循的理论依据个人理解成：参照一段时间内相邻的图像中，像素、亮度与色温的差别很小。所以当面对一段时间内图像我们没必要去对每一幅图像进行完整一帧的编码，而是可以选取这段时间的第一帧图像作为完整编码，而下一幅图像可以记录与第一帧完整编码图像像素、亮度与色温等的差别即可，以此类推循环下去。

什么叫序列呢？上述的这段时间内图像变化不大的图像集我们就可以称之为一个序列。序列可以理解为有相同特点的一段数据。但是如果某个图像与之前的图像变换很大，很难参考之前的帧来生成新的帧，那么久结束删一个序列，开始下一段序列。重复上一序列的做法，生成新的一段序列。

## 帧类型
H264结构中，一个视频图像编码后的数据叫做一帧，一帧由一个片（slice）或多个片组成，一个片由一个或多个宏块（MB）组成，一个宏块由16x16的yuv数据组成。宏块作为H264编码的基本单位。 
在H264协议内定义了三种帧，分别是I帧、B帧与P帧。I帧就是之前所说的一个完整的图像帧，而B、帧与P帧所对应的就是之前说的不编码全部图像的帧。P帧与B帧的差别就是P帧是参考之前的I帧而生成的，而B帧是参考前后图像帧编码生成的。

## GOP(画面组)
GOP我个人也理解为跟序列差不多意思，就是一段时间内变化不大的图像集。GOP结构一般有两个数字，如M=3，N=12。M指定I帧和P帧之间的距离，N指定两个I帧之间的距离。上面的M=3，N=12，GOP结构为：IBBPBBPBBPBBI。在一个GOP内I frame解码不依赖任何的其它帧，p frame解码则依赖前面的I frame或P frame，B frame解码依赖前最近的一个I frame或P frame 及其后最近的一个P frame。

## H264压缩方式
H264采用的核心算法是帧内压缩和帧间压缩，帧内压缩是生成I帧的算法，帧间压缩是生成B帧和P帧的算法。
帧内（Intraframe）压缩也称为空间压缩（Spatialcompression）。当压缩一帧图像时，仅考虑本帧的数据而不考虑相邻帧之间的冗余信息，这实际上与静态图像压缩类似。帧内一般采用有损压缩算法，由于帧内压缩是编码一个完整的图像，所以可以独立的解码、显示。帧内压缩一般达不到很高的压缩，跟编码jpeg差不多。
帧间（Interframe）压缩的原理是：相邻几帧的数据有很大的相关性，或者说前后两帧信息变化很小的特点。也即连续的视频其相邻帧之间具有冗余信息,根据这一特性，压缩相邻帧之间的冗余量就可以进一步提高压缩量，减小压缩比。帧间压缩也称为时间压缩（Temporalcompression），它通过比较时间轴上不同帧之间的数据进行压缩。帧间压缩一般是无损的。帧差值（Framedifferencing）算法是一种典型的时间压缩法，它通过比较本帧与相邻帧之间的差异，仅记录本帧与其相邻帧的差值，这样可以大大减少数据量。

Step1：分组，也就是将一系列变换不大的图像归为一个组，也就是一个序列，也可以叫GOP（画面组）；
Step2：定义帧，将每组的图像帧归分为I帧、P帧和B帧三种类型；
Step3：预测帧， 以I帧做为基础帧,以I帧预测P帧,再由I帧和P帧预测B帧;
Step4：数据传输， 最后将I帧数据与预测的差值信息进行存储和传输。 
## H264码流结构
我认为在具体讲述NAL单元前，十分有必要先了解一下H264的码流结构；在经过编码后的H264的码流，H264码流是由一个个的NAL单元组成，其中SPS、PPS、IDR和SLICE是NAL单元某一类型的数据。

## H264的NAL结构
在实际的网络数据传输过程中H264的数据结构是以NALU（NAL单元）进行传输的，传输数据结构组成为[NALU Header]+[RBSP]：
从之前的分析我们可以知道，VCL层编码后的视频帧数据，帧有可能是I/B/P帧，这些帧也可能是属于不同的序列之中；同一序列也还有相应的序列参数集与图片参数集；综上所述，想要完成准确无误视频的解码，除了需要VCL层编码出来的视频帧数据，同时还需要传输序列参数集和图像参数集等等，所以RBSP不单纯只保存I/B/P帧的数据编码信息，还有其他信息也可能出现在里面。
上面知道NAL单元是作为实际视频数据传输的基本单元，NALU头是用来标识后面RBSP是什么类型的数据，同时记录RBSP数据是否会被其他帧参考以及网络传输是否有错误，所以针对NAL头和RBSP的作用以及结构与所承载的数据需要做个简单的了解；

## SPS/PPS/Slice Header
H.264码流第一个 NALU是 SPS（序列参数集Sequence Parameter Set）
对应H264标准文档 7.3.2.1 序列参数集的语法进行解析
H.264码流第二个 NALU是 PPS（图像参数集Picture Parameter Set）
对应H264标准文档 7.3.2.2 序列参数集的语法进行解析
H.264码流第三个 NALU 是 IDR（即时解码器刷新）
对应H264标准文档 7.3.3 序列参数集的语法进行解析

SDP中的H.264的SPS和PPS串，包含了初始化H.264解码器所需要的信息参数，包括编码所用的profile，level，图像的宽和高，deblock滤波器等。

## H264中I帧和IDR帧的区别

I和IDR帧都是使用帧内预测的。它们都是同一个东西而已,在编码和解码中为了方便，要首个I帧和其他I帧区别开，所以才把第一个首个I帧叫IDR，这样就方便控制编码和解码流程。IDR帧的作用是立刻刷新,使错误不致传播,从IDR帧开始,重新算一个新的序列开始编码。而I帧不具有随机访问的能力，这个功能是由IDR承担，IDR会导致DPB（参考帧列表——这是关键所在）清空，而I不会。IDR图像一定是I图像，但I图像不一定是IDR图像。一个序列中可以有很多的I图像，I图像之后的图像可以引用I图像之间的图像做运动参考。一个序列中可以有很多的I图像，I图像之后的图象可以引用I图像之间的图像做运动参考。

对于IDR帧来说，在IDR帧之后的所有帧都不能引用任何IDR帧之前的帧的内容，与此相反，对于普通的I-帧来说，位于其之后的B-和P-帧可以引用位于普通I-帧之前的I-帧。从随机存取的视频流中，播放器永远可以从一个IDR帧播放，因为在它之后没有任何帧引用之前的帧。但是，不能在一个没有IDR帧的视频中从任意点开始播放，因为后面的帧总是会引用前面的帧。
h264编码的帧由大到小依次为：
I > P > B
（互相之间约有5倍的差距）
x264的编码耗时由长到短依次为：
P > B > I


# S5P6818编解码使用前提
需要将Platform文件夹下的库文件编译，
linux/platform/s5p6818/modules/coda960/nx_vpu.ko
必须要加载到内核中

虽然这个nexell开发的多媒体处理库写的不伦不类，可以说是很挫，而且没有
任何开发文档，但是在只有这个了，自己写也搞不定，鬼知道他的编解码功能
具体怎么用。所以就忍耐以下看看这个库具体怎么用吧。

以下是在Makefile中使用这个库的脚本
需要给出自己的build.env目录位置
和ffmpeg/lib位置

```sh
########################################################################
# Get Linux Build Enviornment:
include /home/swann/SDK/EXYNOS6818/NEWSOURCE/linux/linux/platform/s5p6818/build.env

######################################################################
# Build options
INCLUDE += -I./
INCLUDE += -I$(LIBSDIR)/include -I$(LIBSDIR)/include/theoraparser
LIBRARY	+= -L$(LIBSDIR)/lib -L$(LIBSDIR)/lib/ratecontrol 
LIBRARY += -lnxvpu -lnxdsp -lnxvip -lnxv4l2 -lnxvmem -lnxvidrc
LIBRARY += -ltheoraparser
LIBRARY	+=  -L/home/swann/SDK/EXYNOS6818/SDK/ffmpeg/lib -lavformat -lavdevice -lavcodec -lavutil -lavfilter -lpostproc -lswscale -lswresample -lstdc++ -lm

######################################################################
# Target
CPPOBJS	:= \
	MediaExtractor.o	\
	CodecInfo.o			\
	NX_Queue.o			\
	NX_Semaphore.o		\
	Util.o				\
	VpuDecTest.o		\
	VpuEncTest.o		\
	VpuJpgTest.o		\
	vpu.o		\
	main.o

CFLAGS	+= -g

TARGET:= codec_tests

######################################################################
# Build
OBJS	:= $(COBJS) $(CPPOBJS)

all:	\
	$(THEORAPARSER) \
	$(TARGET)

$(TARGET):	depend $(OBJS)
	$(CC) $(CPPFLAGS) $(OBJS) -o $@ $(LIBRARY)

clean:
	rm -f $(OBJS) $(TARGET) .depend

#########################################################################
# Dependency
ifeq (.depend,$(wildcard .depend))
include .depend
endif

SRCS := $(COBJS:.o=.c) $(CPPOBJS:.o=.cpp) $(APPOBJS:.o=.c)
INCS := $(INCLUDE)
depend dep:
	$(CC) -M $(CFLAGS) $(INCS) $(SRCS) > .depend

```

CMake示例
```sh
    #添加环境所需的头文件
    MESSAGE(USE_S5P6818_LIB)
    set(FFMPEGDIR /home/swann/SDK/EXYNOS6818/SDK/ffmpeg)
    set(OPENCVDIR /home/swann/SDK/EXYNOS6818/SDK/opencv/install)
    
    list(APPEND FFmpeg_LIBS  avformat avdevice avcodec avutil avfilter postproc swscale swresample)
    add_link_options(-L${FFMPEGDIR}/lib -lpthread)
    list(APPEND OpenCV_LIBS   opencv_imgcodecs opencv_dnn opencv_imgproc opencv_core )
    add_link_options(-L${OPENCVDIR}/lib)
    include_directories (${FFMPEGDIR}/include)
    include_directories (${OPENCVDIR}/include)

    #添加平台摄像头文件夹
    aux_source_directory(source/camera/camera_6124   PLATFORM_CAMERA)  
    include_directories (source/camera/camera_6124)

    #添加平台编解码器文件夹
    aux_source_directory(source/codec/encode/encode_6818   PLATFROM_ENCODE)  
    include_directories (source/codec/encode/encode_6818)

    #写入platform文件夹中nexell提供的库
    set (NXPLIBSDIR   /home/swann/SDK/EXYNOS6818/NEWSOURCE/linux/linux/platform/s5p6818/library)
    #写入内核所在位置
    set (KERNDIR      /home/swann/SDK/EXYNOS6818/NEWSOURCE/linux/linux/kernel/kernel-3.4.39)
    include_directories (${KERNDIR}/arch/arm/mach-s5p6818/include)
    include_directories (${KERNDIR}/include)
    include_directories (${NXPLIBSDIR}/src/libion)
    include_directories (${NXPLIBSDIR}/src/libnxv4l2)
    include_directories (${NXPLIBSDIR}/include/theoraparser)
    include_directories (${NXPLIBSDIR}/include)
    add_compile_options(-lz -lm -lrt -Wall -O2 -Wextra -Wcast-align -Wno-unused-parameter -Wshadow -Wwrite-strings -Wcast-qual -fno-strict-aliasing -fstrict-overflow -fsigned-char -fno-omit-frame-pointer -fno-optimize-sibling-calls -Wnon-virtual-dtor)
    set(CMAKE_C_COMPILER "arm-cortex_a9-linux-gnueabi-gcc")
    set(CMAKE_CXX_COMPILER "arm-cortex_a9-linux-gnueabi-g++")
    
    list(APPEND NXP_LIBS  ion v4l2-nexell m stdc++ nxvpu
    nxdsp nxvip nxv4l2 nxvmem nxvidrc theoraparser
    )
    add_link_options(-L${NXPLIBSDIR}/lib 
    -L${NXPLIBSDIR}/lib/ratecontrol
    -L${NXPLIBSDIR}/src/libion
    -L${NXPLIBSDIR}/src/libnxv4l2
    )
    
    add_executable(vpss_encode ${PLATFORM_CAMERA} ${PLATFROM_ENCODE} ${BASE1_SRC} ${BASE2_SRC} ${BASE3_SRC} ${BASE4_SRC} ${VPSS_ENCODE_APP})
    target_link_libraries(vpss_encode ${OpenCV_LIBS})
    target_link_libraries(vpss_encode ${FFmpeg_LIBS})
    target_link_libraries(vpss_encode ${NXP_LIBS})

    add_executable(vi_multichannel ${PLATFORM_CAMERA} ${BASE1_SRC} ${BASE2_SRC} ${BASE3_SRC} ${BASE4_SRC} ${VI_MUTILCHANNEL_APP})
    target_link_libraries(vi_multichannel ${OpenCV_LIBS})
    target_link_libraries(vi_multichannel ${FFmpeg_LIBS})
    target_link_libraries(vi_multichannel ${NXP_LIBS} dl)

    add_executable(vi_framebuffer  ${BASE1_SRC} ${BASE2_SRC} ${BASE3_SRC} ${BASE4_SRC} ${VI_FRAMEBUFFER_APP})
    target_link_libraries(vi_framebuffer ${OpenCV_LIBS})
    target_link_libraries(vi_framebuffer ${FFmpeg_LIBS})
```


# S5P6818编解码能力
如下需要注意的是在编码方面6818仅支持四种编码模式，不包括H265
```cpp
typedef enum {
	//  Decoders
	NX_AVC_DEC      = 0x00,         // H.264( AVC )
	NX_VC1_DEC      = 0x01,         // WMV9
	NX_MP2_DEC      = 0x02,         // Mpeg2 Video
	NX_MP4_DEC      = 0x03,         // Mpeg4 Video
	NX_H263_DEC     = 0x04,         // H.263
	NX_DIV3_DEC     = 0x05,         // Divx 3.11(MS Mpeg4 V3)
	NX_RV_DEC       = 0x06,         // Real Video
	NX_THEORA_DEC   = 0x07,         // Theora
	NX_VP8_DEC      = 0x08,         // VP8
	NX_JPEG_DEC     = 0x09,         // JPEG
	NX_HEVC_DEC		= 0x0A,			// H.265( HEVC )

	//  Encoders
	NX_AVC_ENC      = 0x10,
	NX_MP4_ENC      = 0x12,
	NX_H263_ENC     = 0x13,
	NX_JPEG_ENC     = 0x20,         // JPEG Encoder
} VID_TYPE_E;
```

以下是对编码功能要使用的API函数

调用方法 : NX_VidEncOpen() --> NX_VidEncInit()  -->NX_VidEncEncodeFrame()或NX_VidEncJpegRunFrame() --> 
NX_VidEncClose()


NX_VidEncEncodeFrame 数据输入为NX_VID_ENC_IN        需要填充图像数据，格式为NV12
NX_VidEncJpegRunFrame 数据输入为NX_VID_MEMORY_HANDLE 需要填充图像数据，格式为IYUV

NX_VidEncGetSeqInfo 会返回一个文件信息头，如果保存为文件的话，需要先将信息头保存
对于H264 这个信息头就是SPS PPS

```cpp
NX_VID_ENC_HANDLE NX_VidEncOpen( VID_TYPE_E eCodecType, int32_t *piInstanceIdx );
VID_ERROR_E NX_VidEncClose( NX_VID_ENC_HANDLE hEnc );
VID_ERROR_E NX_VidEncInit( NX_VID_ENC_HANDLE hEnc, NX_VID_ENC_INIT_PARAM *pstParam );
VID_ERROR_E NX_VidEncGetSeqInfo( NX_VID_ENC_HANDLE hEnc, uint8_t *pbySeqBuf, int32_t *piSeqBufSize );
VID_ERROR_E NX_VidEncEncodeFrame( NX_VID_ENC_HANDLE hEnc, NX_VID_ENC_IN *pstEncIn, NX_VID_ENC_OUT *pstEncOut );
VID_ERROR_E NX_VidEncChangeParameter( NX_VID_ENC_HANDLE hEnc, NX_VID_ENC_CHG_PARAM *pstChgParam );

VID_ERROR_E NX_VidEncJpegGetHeader( NX_VID_ENC_HANDLE hEnc, uint8_t *pbyJpgHeader, int32_t *piHeaderSize );
VID_ERROR_E NX_VidEncJpegRunFrame( NX_VID_ENC_HANDLE hEnc, NX_VID_MEMORY_HANDLE hInImage, NX_VID_ENC_OUT *pstEncOut );
VID_ERROR_E NX_VidGetVersion( NX_VID_VERSION *pstVersion );
```
编码控制变量
```cpp
typedef struct tNX_VID_ENC_INIT_PARAM{
    	int32_t width;                      //图像宽度                        
        int32_t height;                     //图像宽度    
        int32_t gopSize;                    //关键帧间隔
        int32_t fpsNum;                     //帧率
        int32_t fpsDen;                     //直接给1
        // 速率控制参数 (仅在 enableRC ==1时使用)
        int32_t enableRC;                       // 使能速率控制
        int32_t RCAlgorithm;                    // 速率控制算法选择
        uint32_t bitrate;                       // Target bitrate in bits per second
        int32_t maximumQp;                      // 最大量化参数
        //编码我们一般采用就是两种思想，在空间域上采用帧内压缩，利用数据的空间相关性进行压缩，这种压缩思想实现基本就是图片的压缩算法。另外一种就是一种利用时域的数据相关性进行压缩，采用参考参考帧和预测帧之间的宏块计算残差在此基础上进行压缩。一般用“残差”Dn 来表示当前块和参考块之间的误差。将残差 Dn 进一步进行离散余弦变换 DCT后对变换系数进行量化可以进一步压缩数据量。其中该压缩过程是有损的，一般地随着量化参数QP的扩大，图像的损失将变大。解码过程需要进行一次反量化-反变换IDCT 还原残差，后再根据参考宏块还原原始图像。实际上现有的码率控制算法主要是通过调整离散余弦变换的量化参数大小输出目标码 率。实际上,量化参数(QP)反映了空间细节压缩情况,如 QP 小,大部分的细节都会被保留，码 率增大。QP 增大，一些细节丢失，码率降低，但图像失真加强和质量下降。也就是说，QP 和比特率成反比的关系。

        int32_t disableSkip;                    // 是否禁止跳帧 如果太卡算法可能直接跳帧
        int32_t RCDelay;                        // 一个不知道干什么的延时 0 ~ 0x7FFF
                                                // 0不检查参考解码器缓冲区延迟约束。
        uint32_t rcVbvSize;                     // 参考解码器缓冲区大小（字节）
                                                // 如果RCAlgorithm为1，则默认值为2秒。 
                                                // 如果RCAlgorithm为0且RCDelay为0，则忽略此有效值
        int32_t gammaFactor;                    // User gamma factor
                                                // It is valid only when RCAlgorithm is 0.
        int32_t RcMode;

        int32_t initialQp;                     	// 初始量化参数 
                                                // 如果enableRC为1，RCAlgorithm为1，且值为0，则计算该值。 

        int32_t numIntraRefreshMbs;             // Intra MB refresh number.(Cyclic Intra Refresh)
        int32_t searchRange;                    // 搜索范围估计  (0 : 128 x 64, 1 : 64 x 32, 2 : 32 x 16, 3 : 16 x 16)

        //  输入图像格式
        int32_t chromaInterleave;               // 给个1
        int32_t rotAngle;                       // 旋转角度
        int32_t mirDirection;                   // 输入方向 给0就行 
        //  H264特有变量
        int32_t enableAUDelimiter;              // 是否插入分届符
        //  JPEG特有变量
        int32_t jpgQuality;                     // 1~100
    }NX_VID_ENC_INIT_PARAM;
```

具体使用程序参考：example/vpss_encode.cpp
实现了两路摄像头分别编码保存的程序

